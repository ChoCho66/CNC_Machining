{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "SKIP_LENGTH = 2048\n",
    "WINDOW_SIZE = 4096\n",
    "OVERLAP_LENGTH = 2048\n",
    "SAMPLE_RATE = 2000 # Hz\n",
    "SCALING = True\n",
    "# SCALING = False\n",
    "# TYPE_ANOMALY_DETECTION = \"Novelty\"\n",
    "TYPE_ANOMALY_DETECTION = \"Outlier\"\n",
    "# TYPE_DOMAIN = \"freq\"\n",
    "TYPE_DOMAIN = \"time\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印出今日日期\n",
    "import datetime\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "TODAY = datetime.datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load X_raw_data.pkl, y_raw_data.pkl\n",
    "with open(\"X_raw_data.pkl\", \"rb\") as file:\n",
    "    X_raw_data = pickle.load(file)\n",
    "\n",
    "with open(\"y_raw_data.pkl\", \"rb\") as file:\n",
    "    y_raw_data = pickle.load(file)\n",
    "    \n",
    "# for arr in X_raw_data:\n",
    "#     arr[:, 2] += 1000\n",
    "\n",
    "def process_time_series_with_overlap(data, skip_length=2048, window_size=4096, overlap_length=2048):\n",
    "    \"\"\"\n",
    "    處理 time series data，去除開頭資料並切分成固定長度、具有 overlap 的片段。\n",
    "    \n",
    "    :param data: numpy array, shape = (length, 3)\n",
    "    :param skip_length: 開頭跳過的資料長度, 預設 2048\n",
    "    :param window_size: 每段切分的長度, 預設 4096\n",
    "    :param overlap_length: 每段之間的重疊長度, 預設 2048\n",
    "    :return: 切分後的資料列表，每個元素為 numpy array\n",
    "    \"\"\"\n",
    "    # 計算每次移動的步數 (window_size - overlap_length)\n",
    "    step_length = window_size - overlap_length\n",
    "\n",
    "    # 去掉開頭的資料\n",
    "    data = data[skip_length:]\n",
    "    \n",
    "    # 切分資料，加入 overlap\n",
    "    segments = [data[i:i + window_size] for i in range(0, len(data) - window_size + 1, step_length)]\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(len(X_raw_data)):\n",
    "    X_data.extend(process_time_series_with_overlap(X_raw_data[i]))\n",
    "    if 'good' in y_raw_data[i]:\n",
    "        y_data.extend([0] * len(process_time_series_with_overlap(X_raw_data[i])))\n",
    "    else:\n",
    "        y_data.extend([1] * len(process_time_series_with_overlap(X_raw_data[i])))\n",
    "\n",
    "del X_raw_data\n",
    "\n",
    "# X_data_abs = np.abs(X_data)\n",
    "# x_abs_max, y_abs_max, z_abs_max = X_data_abs[:,:,0].max(), X_data_abs[:,:,1].max(), X_data_abs[:,:,2].max()\n",
    "\n",
    "# ## Scaling\n",
    "# if SCALING:\n",
    "#     for i,m_i in enumerate([x_abs_max, y_abs_max, z_abs_max]):\n",
    "#         X_data[:,:,i] = X_data[:,:,i]/m_i\n",
    "    \n",
    "good_indices = [index for index, value in enumerate(y_data) if value == 0]\n",
    "bad_indices = [index for index, value in enumerate(y_data) if value == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Scaling\n",
    "if SCALING:\n",
    "    # 計算每個特徵的均值和標準差\n",
    "    mean = np.mean(X_data, axis=(0,1), keepdims=True)  # shape: (1, 1, 3)\n",
    "    std = np.std(X_data, axis=(0,1), keepdims=True)  # shape: (1, 1, 3)\n",
    "\n",
    "    # 進行標準化\n",
    "    X_data = (X_data) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean and std\n",
    "np.save(f'{TODAY}-mean_std_{TYPE_DOMAIN}.npy', [mean, std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X_data, y_data by np.save\n",
    "np.save(f'{TODAY}-X_data_{TYPE_DOMAIN}.npy', X_data)\n",
    "np.save(f'{TODAY}-y_data_{TYPE_DOMAIN}.npy', y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83340, 4096, 3), 83340)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03080153587712983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.sum()/len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05673802,  1.38298965,  0.01712689],\n",
       "       [-0.05267331,  1.65574648, -0.00557231],\n",
       "       [-0.02176359,  1.44165735, -0.0352587 ],\n",
       "       ...,\n",
       "       [-0.14588435,  0.10469603,  0.07509945],\n",
       "       [-0.13613788,  0.54478519,  0.06783984],\n",
       "       [-0.00996463,  0.2753322 , -0.05027105]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 01:09:49.159609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-20 01:09:50.034106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2025-01-20 01:09:50.034243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2025-01-20 01:09:50.034252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2025-01-20 01:09:51.124944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.133521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.133795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.134444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-20 01:09:51.135189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.135446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.135645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.643323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.643656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.643877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-20 01:09:51.644069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21969 MB memory:  -> device: 0, name: GRID P40-24Q, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 4096, 3)]         0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 227)               2233      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 4096, 3)           237269    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 239,502\n",
      "Trainable params: 239,222\n",
      "Non-trainable params: 280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def encoder(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Conv1\n",
    "    x = layers.Conv1D(filters=3, kernel_size=127, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # MaxPooling1\n",
    "    x = layers.MaxPooling1D(pool_size=3)(x)\n",
    "    \n",
    "    # Conv2\n",
    "    x = layers.Conv1D(filters=3, kernel_size=11, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # MaxPooling2\n",
    "    x = layers.MaxPooling1D(pool_size=3)(x)\n",
    "    \n",
    "    # Conv3\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # MaxPooling3\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # Conv4\n",
    "    x = layers.Conv1D(filters=1, kernel_size=1, padding='same')(x)\n",
    "    \n",
    "    # Flatten\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Output for encoder\n",
    "    encoder_output = x\n",
    "    \n",
    "    # Create encoder model\n",
    "    encoder_model = models.Model(inputs, encoder_output, name='encoder')\n",
    "    return encoder_model\n",
    "\n",
    "def decoder(encoded_shape):\n",
    "    # Start with the encoded shape\n",
    "    inputs = layers.Input(shape=(encoded_shape,))\n",
    "    \n",
    "    # Reshape to the last convolutional layer output shape\n",
    "    x = layers.Dense(1024)(inputs)  # This should match the flattened size before Conv4\n",
    "    x = layers.Reshape((1024, 1))(x)\n",
    "    \n",
    "    # Upsampling and Conv layers to reconstruct the original input\n",
    "    x = layers.Conv1DTranspose(filters=64, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.UpSampling1D(size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1DTranspose(filters=3, kernel_size=11, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.UpSampling1D(size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1DTranspose(filters=3, kernel_size=127, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # x = layers.ReLU()(x)\n",
    "    outputs = x\n",
    "    \n",
    "    # Final output layer\n",
    "    # outputs = x\n",
    "    # outputs = layers.Conv1DTranspose(filters=3, kernel_size=1, padding='same')(x)\n",
    "    \n",
    "    # Create decoder model\n",
    "    decoder_model = models.Model(inputs, outputs, name='decoder')\n",
    "    return decoder_model\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (4096, 3)\n",
    "\n",
    "# Create encoder and decoder\n",
    "encoder_model = encoder(input_shape)\n",
    "encoded_shape = encoder_model.output_shape[1]  # Get the shape of the encoder output\n",
    "decoder_model = decoder(encoded_shape)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder_input = layers.Input(shape=input_shape)\n",
    "encoded_output = encoder_model(autoencoder_input)\n",
    "decoded_output = decoder_model(encoded_output)\n",
    "\n",
    "autoencoder_model = models.Model(autoencoder_input, decoded_output, name='autoencoder')\n",
    "\n",
    "# Summary of the autoencoder\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 4096, 3)]         0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 4096, 3)           1146      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4096, 3)          12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 4096, 3)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1365, 3)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 1365, 3)           102       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1365, 3)          12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 1365, 3)           0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 455, 3)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 455, 64)           640       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 455, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 455, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 227, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 227, 1)            65        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 227)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,233\n",
      "Trainable params: 2,093\n",
      "Non-trainable params: 140\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 227)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              233472    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 1024, 1)           0         \n",
      "                                                                 \n",
      " conv1d_transpose_3 (Conv1DT  (None, 1024, 64)         256       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 1024, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 1024, 64)          0         \n",
      "                                                                 \n",
      " up_sampling1d_2 (UpSampling  (None, 2048, 64)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_transpose_4 (Conv1DT  (None, 2048, 3)          2115      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 2048, 3)          12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 2048, 3)           0         \n",
      "                                                                 \n",
      " up_sampling1d_3 (UpSampling  (None, 4096, 3)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_transpose_5 (Conv1DT  (None, 4096, 3)          1146      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 4096, 3)          12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237,269\n",
      "Trainable params: 237,129\n",
      "Non-trainable params: 140\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 查看 encoder 部分的摘要\n",
    "encoder_model = encoder(input_shape)\n",
    "encoder_model.summary()\n",
    "\n",
    "# 查看 decoder 部分的摘要\n",
    "latent_dim = encoder_model.output_shape[1]\n",
    "decoder_model = decoder(latent_dim)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data) % 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 01:10:08.689908: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4096327680 exceeds 10% of free system memory.\n",
      "2025-01-20 01:10:15.691090: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4096327680 exceeds 10% of free system memory.\n",
      "2025-01-20 01:10:20.303644: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4096327680 exceeds 10% of free system memory.\n",
      "2025-01-20 01:10:23.985919: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4096327680 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 01:11:01.130596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2025-01-20 01:11:01.942614: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f4ad8002cd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-01-20 01:11:01.942680: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): GRID P40-24Q, Compute Capability 6.1\n",
      "2025-01-20 01:11:01.948641: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-20 01:11:02.069006: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 74s 56ms/step - loss: 0.8929\n",
      "Epoch 2/300\n",
      "652/652 [==============================] - 37s 56ms/step - loss: 0.6552\n",
      "Epoch 3/300\n",
      "652/652 [==============================] - 36s 56ms/step - loss: 0.6259\n",
      "Epoch 4/300\n",
      "310/652 [=============>................] - ETA: 18s - loss: 0.6176"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m autoencoder_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 假设 X_data 是你的训练数据\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 添加 EarlyStopping 回调\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/engine/training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1655\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1656\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    349\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    393\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 394\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/utils/tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/keras/utils/tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/vad-code/.conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# 设置 EarlyStopping 回调\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',          # 监控的指标，可以是 'loss' 或 'val_loss' 等\n",
    "    patience=30,             # 如果连续 10 个 epoch 没有改善，则停止训练\n",
    "    restore_best_weights=True,  # 在停止时恢复最好的权重\n",
    "    verbose=1                # 输出早停信息\n",
    ")\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# 編譯模型\n",
    "autoencoder_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "# 假设 X_data 是你的训练数据\n",
    "history = autoencoder_model.fit(\n",
    "    X_data, X_data,\n",
    "    epochs=3000,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping]  # 添加 EarlyStopping 回调\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取训练过程中的 loss 值\n",
    "loss_values = history.history['loss']\n",
    "# 绘制损失曲线\n",
    "plt.plot(range(1, len(loss_values) + 1), loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# save the plot\n",
    "plt.savefig(f'loss_plot_encode_{TYPE_DOMAIN}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4096, 3)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4096, 3)           1146      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4096, 3)          12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 4096, 3)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1365, 3)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1365, 3)           102       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1365, 3)          12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1365, 3)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 455, 3)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 455, 64)           640       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 455, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 455, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 227, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 227, 1)            65        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 227)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,233\n",
      "Trainable params: 2,093\n",
      "Non-trainable params: 140\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 23:56:48.323484: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4096327680 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2605/2605 [==============================] - 6s 2ms/step\n",
      "[[ 1.1357931   1.2600672   1.1410853  ...  0.07521231 -0.63927263\n",
      "   0.10421687]\n",
      " [ 0.6453032   0.66794574  0.71926254 ... 11.101378   12.649561\n",
      "  10.280287  ]\n",
      " [ 0.648163    0.81354666  0.8891839  ...  0.51959884  0.5881324\n",
      "   0.31169954]\n",
      " ...\n",
      " [-2.935736   -5.463349   -6.4960303  ...  8.277553    3.652892\n",
      "   0.8547929 ]\n",
      " [ 2.946829    3.0669124   3.1494808  ...  3.7426362  11.145738\n",
      "  10.752214  ]\n",
      " [ 2.2583938   2.0914173   1.8535408  ...  1.7194936   1.4449658\n",
      "   0.8134218 ]]\n"
     ]
    }
   ],
   "source": [
    "# 提取 encoder 部分\n",
    "encoder_model = autoencoder_model.get_layer('encoder')\n",
    "\n",
    "# 查看 encoder 部分的模型结构\n",
    "encoder_model.summary()\n",
    "\n",
    "X_data_encode = encoder_model.predict(X_data)\n",
    "# 查看编码后的数据\n",
    "print(X_data_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83340, 227)\n"
     ]
    }
   ],
   "source": [
    "print(X_data_encode.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoded data\n",
    "np.save(f'X_data_encode_{TYPE_DOMAIN}.npy', X_data_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型為 HDF5 文件\n",
    "autoencoder_model.save(f'autoencoder_model_{TYPE_DOMAIN}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型為 Keras 文件\n",
    "autoencoder_model.save(f'autoencoder_model_{TYPE_DOMAIN}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# # 加載 Keras 格式模型\n",
    "# model_keras = load_model(f'autoencoder_model_{TYPE_DOMAIN}.keras')\n",
    "# model_keras.summary()\n",
    "\n",
    "\n",
    "# 假設原始模型是 original_model，並且 encoder 是在原始模型中已經定義的層\n",
    "# encoder = original_model.get_layer(\"encoder\")\n",
    "# 創建新模型，只包含 encoder 部分\n",
    "# encoder_model = Model(inputs=original_model.input, outputs=encoder.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
